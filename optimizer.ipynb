{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer backbone\n",
    "network1 = Twolayer()\n",
    "optimizer = SGD()\n",
    "\n",
    "param = network1.params\n",
    "grad = network1.grad\n",
    "\n",
    "optimizer.update(param, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#momentum\n",
    "\n",
    "class Momentum:\n",
    "    def __init__(self, momentum, lr):\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.v = None\n",
    "    \n",
    "    def update(self, param, grad):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for keys, vec in param.items():\n",
    "                self.v[keys] = np.zeros_like(vec) #각 parameter마다 shape 다를 수 있으니 이렇게 해야 함\n",
    "        for keys in param.keys():\n",
    "            self.v[keys] = self.momentum * self.v[keys] - self.lr * grad[keys]\n",
    "            param[keys] = param[keys] + self.v[keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nesterov():\n",
    "    def __init__(self, momentum, lr):\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, param, grad):\n",
    "        if self.v is None:\n",
    "            pass\n",
    "        \n",
    "        for key in param.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grad[key]\n",
    "            self.param[key] = self.param[key] + self.momentum * self.v[key] - self.lr * grad[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "    def update(self, param, grad):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in grad.items():\n",
    "                self.h[key] = np.zeros_liks(val)\n",
    "        \n",
    "        for key in grad.keys():\n",
    "            self.h[key] += grad[key] * grad[key]\n",
    "            denom = np.sqrt(self.h[key] + 1e-7)\n",
    "            param[key] -= self.lr * grad[key] / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rmsprop:\n",
    "    def __init__(self, lr, decay):\n",
    "        self.lr = lr\n",
    "        self.decay = decay\n",
    "        self.h = None\n",
    "    def update(self, param, grad):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in grad.items():\n",
    "                self.h[key] = np.zeros_liks(val)\n",
    "        \n",
    "        for key in grad.keys():\n",
    "            self.h[key] += self.decay*self.h[key] + (1-self.decay)*grad[key] * grad[key]\n",
    "            denom = np.sqrt(self.h[key] + 1e-7)\n",
    "            param[key] -= self.lr * grad[key] / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, beta1, beta2, lr, iter):\n",
    "        #hyperparameter\n",
    "        self.v = None\n",
    "        self.h = None \n",
    "    \n",
    "    def update(self, param, grad):\n",
    "        #bias_v, h\n",
    "        if v is None:\n",
    "            self.v = {}\n",
    "            self.h = {}\n",
    "\n",
    "            for key, val in param.items():\n",
    "                self.v = np.zeros_like(val)\n",
    "                self.h = np.zeors_like(val)\n",
    "\n",
    "        #bias_v, h  \n",
    "        \n",
    "        for keys in param.keys():\n",
    "            self.v[keys] = bias_v / 1-(beta1)**(iter+1)\n",
    "            self.h[keys] = bias_h / 1-(beta1)**(iter+1)\n",
    "\n",
    "            self.param[keys] = self.param[keys] - lr *  v[keys] / (np.sqrt(h) + 1e-7)\n",
    "\n",
    "        \n",
    "        self.iter +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nesterov sgd\n",
    "\n",
    "class Nesterov:\n",
    "\n",
    "  \"\"\"Nesterov's Accelerated Gradient (http://arxiv.org/abs/1212.0901)\"\"\"\n",
    "\n",
    "  def __init__(self, lr=0.01, momentum=0.9):\n",
    "    self.lr = lr\n",
    "    self.momentum = momentum\n",
    "    self.v = None\n",
    "\n",
    "  def update(self, params, grads):\n",
    "    if self.v is None:\n",
    "      self.v = {}\n",
    "      for keys, vals in params.items():\n",
    "        self.v[keys] = np.zeros_like(vals) #이 like 잘 기억\n",
    "    \n",
    "    for keys in self.v.keys():\n",
    "      tem_v = self.v[keys]\n",
    "      self.v[keys] = self.momentum * self.v[keys] - self.lr * grads[keys] #틀렸던 부분: grads[self.v[keys]]\n",
    "      params[keys] += self.v[keys] + self.momentum * (self.v[keys]-tem_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad:\n",
    "    def __init__(self, lr = 0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for keys, vals in params.items():\n",
    "                self.h[keys] = np.zeros_like(vals)\n",
    "        \n",
    "        for keys in self.h.keys():\n",
    "            self.h[keys] += grads[keys] * grads[keys]\n",
    "            denomitator = (np.sqrt(self.h[keys])+1e-7)\n",
    "            params[keys] -= self.lr * grads[keys] / denomitator  #params[keys] = params[keys] - self.lr * grads[keys] / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.41421356 1.73205081]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "print(np.sqrt(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "\n",
    "  \"\"\"RMSprop\"\"\"\n",
    "\n",
    "  def __init__(self, lr=0.01, decay_rate = 0.99):\n",
    "    self.lr = lr\n",
    "    self.decay_rate = decay_rate\n",
    "    self.h = None\n",
    "\n",
    "  def update(self, params, grads):\n",
    "    # 'ppp' exercise \n",
    "    if self.h is None:\n",
    "      self.h = {}\n",
    "      for keys, vals in params.items():\n",
    "        self.h[keys] = np.zeros_like(params[keys])  #각 parameter 마다 dimension이 다를 수 있으니 e.g. W1, W2, b1, b2 등에 대해 반복\n",
    "\n",
    "    for keys in params.keys(): #각 parameter e.g. W1, W2, b1, b2 등에 대해 반복\n",
    "        temp_h = self.h[keys]\n",
    "        self.h[keys] = self.decay_rate * temp_h + (1-self.decay_rate)*(grads[keys]*grads[keys])\n",
    "        denominator = np.sqrt(self.h[keys]) + 1e-7\n",
    "        params[keys] = params[keys] - self.lr * grads[keys] / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0  # for bias correction\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m = {}\n",
    "            for keys, vals in params.items():\n",
    "                self.m[keys] = np.zeros_like(params[keys]) \n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for keys, vals in params.items():\n",
    "                self.v[keys] = np.zeros_like(params[keys]) \n",
    "\n",
    "        for keys in params.keys():\n",
    "            temp_m = self.m[keys]\n",
    "            biased_m = self.beta1 * temp_m + (1-self.beta1) * grads[keys]\n",
    "            temp_v = self.v[keys]\n",
    "            biased_v = self.beta2 * temp_v + (1-self.beta2) * grads[keys] * grads[keys]\n",
    "\n",
    "            self.m[keys] = biased_m / (1-self.beta1**(self.iter+1))\n",
    "            self.v[keys] = biased_v / (1-self.beta2**(self.iter+1))\n",
    "\n",
    "            denominator = np.sqrt(self.v[keys]) + 1e-7\n",
    "            params[keys] = params[keys] - self.lr * self.m[keys] / denominator\n",
    "\n",
    "            self.iter += 1 #빠뜨리지 않도록 주의하기!\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
